"""
Clean Streamlit app for DocInsight - Production-ready web interface
"""
import streamlit as st
import os
import json
import time
from pathlib import Path
from typing import Optional

# Defensive imports
try:
    import fitz  # PyMuPDF
    HAS_PYMUPDF = True
except ImportError:
    HAS_PYMUPDF = False

try:
    from docx import Document
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

from corpus_builder import CorpusIndex
from enhanced_pipeline import PlagiarismDetector

# Initialize detector (cached)
@st.cache_resource
def load_detector():
    """Load and cache the plagiarism detector."""
    try:
        st.info("Initializing DocInsight... This may take a moment.")
        
        # Create corpus index
        corpus_index = CorpusIndex(target_size=2000)  # Smaller for web app performance
        corpus_index.load_or_build()
        
        # Try to build FAISS index
        if corpus_index.build_index():
            st.success(f"âœ… Loaded {len(corpus_index.sentences)} sentences with FAISS indexing")
        else:
            st.warning("âš ï¸ Running in fallback mode (no FAISS indexing)")
        
        # Create detector
        detector = PlagiarismDetector(corpus_index)
        
        return detector
    except Exception as e:
        st.error(f"Failed to initialize detector: {e}")
        return None

def extract_text_from_file(uploaded_file) -> Optional[str]:
    """Extract text from uploaded file."""
    file_type = uploaded_file.name.lower().split('.')[-1]
    
    try:
        if file_type == 'txt':
            return str(uploaded_file.read(), "utf-8")
        
        elif file_type == 'pdf' and HAS_PYMUPDF:
            # Save uploaded file temporarily
            temp_path = Path(f"./cache/{uploaded_file.name}")
            temp_path.parent.mkdir(exist_ok=True)
            
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # Extract text using PyMuPDF
            doc = fitz.open(temp_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            
            # Clean up
            temp_path.unlink()
            return text
        
        elif file_type in ['docx', 'doc'] and HAS_DOCX:
            # Save uploaded file temporarily
            temp_path = Path(f"./cache/{uploaded_file.name}")
            temp_path.parent.mkdir(exist_ok=True)
            
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # Extract text using python-docx
            doc = Document(temp_path)
            text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            
            # Clean up
            temp_path.unlink()
            return text
        
        else:
            st.error(f"Unsupported file type: {file_type}")
            return None
            
    except Exception as e:
        st.error(f"Error extracting text: {e}")
        return None

def display_analysis_results(results: dict):
    """Display analysis results in a nice format."""
    overall_stats = results['overall_stats']
    sentence_analyses = results['sentence_analyses']
    
    # Overall statistics
    st.subheader("ğŸ“Š Overall Analysis")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Sentences", overall_stats['total_sentences'])
    
    with col2:
        st.metric("Avg Similarity Score", f"{overall_stats['avg_fused_score']:.3f}")
    
    with col3:
        st.metric("Max Similarity Score", f"{overall_stats['max_fused_score']:.3f}")
    
    with col4:
        high_risk_pct = overall_stats['high_risk_ratio'] * 100
        st.metric("High Risk %", f"{high_risk_pct:.1f}%")
    
    # Risk summary
    st.subheader("ğŸš¨ Risk Assessment")
    
    high_count = overall_stats['high_confidence_count']
    medium_count = overall_stats['medium_confidence_count']
    low_count = overall_stats['low_confidence_count']
    
    if high_count > 0:
        st.error(f"âš ï¸ **HIGH RISK**: {high_count} sentences with high similarity detected!")
    elif medium_count > 0:
        st.warning(f"âš ï¸ **MEDIUM RISK**: {medium_count} sentences with medium similarity detected.")
    else:
        st.success("âœ… **LOW RISK**: No high-similarity content detected.")
    
    # Detailed results
    st.subheader("ğŸ” Detailed Sentence Analysis")
    
    for i, analysis in enumerate(sentence_analyses):
        sentence = analysis['sentence']
        confidence = analysis['confidence']
        fused_score = analysis['fused_score']
        matches = analysis['matches']
        
        # Color code based on confidence
        if confidence == "HIGH":
            st.error(f"**Sentence {i+1}** (Score: {fused_score:.3f}) - {confidence} RISK")
        elif confidence == "MEDIUM":
            st.warning(f"**Sentence {i+1}** (Score: {fused_score:.3f}) - {confidence} RISK")
        else:
            st.info(f"**Sentence {i+1}** (Score: {fused_score:.3f}) - {confidence} RISK")
        
        st.write(f"*Text:* {sentence}")
        
        if matches:
            st.write("**Similar content found:**")
            for j, match in enumerate(matches[:3]):  # Show top 3 matches
                st.write(f"  {j+1}. *Similarity: {match['similarity']:.3f}* - {match['text']}")
        
        st.write("---")

def main():
    st.set_page_config(
        page_title="DocInsight Enhanced",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("ğŸ” DocInsight Enhanced - AI-Powered Plagiarism Detection")
    st.markdown("### Production-Ready Version with Real Dataset Integration")
    
    # Header with key features
    st.markdown("""
    **ğŸ‰ Major Upgrade**: Now powered by real datasets with enhanced ML models!
    
    **Key Features:**
    - ğŸš€ **One-click analysis** - just upload your document
    - ğŸ§  **Advanced ML models** for semantic similarity detection
    - ğŸ“Š **Confidence scoring** with detailed risk assessment
    - ğŸŒ **Multi-domain corpus** covering academic, technical, and general content
    - âš¡ **Fast processing** with optimized indexing
    """)
    
    # Load detector
    detector = load_detector()
    
    if detector is None:
        st.error("âŒ Failed to initialize DocInsight. Please check the logs and try again.")
        return
    
    # File upload section
    st.subheader("ğŸ“„ Upload Your Document")
    
    uploaded_file = st.file_uploader(
        "Choose a file",
        type=['txt', 'pdf', 'docx', 'doc'],
        help="Supported formats: TXT, PDF, DOCX, DOC"
    )
    
    if uploaded_file is not None:
        st.success(f"âœ… File uploaded: {uploaded_file.name}")
        
        # Extract text
        with st.spinner("Extracting text from document..."):
            text = extract_text_from_file(uploaded_file)
        
        if text:
            st.success(f"âœ… Extracted {len(text)} characters")
            
            # Show preview
            with st.expander("ğŸ“– Document Preview"):
                st.text_area("Content preview", text[:1000] + "..." if len(text) > 1000 else text, height=200)
            
            # Analysis button
            if st.button("ğŸ” Analyze for Plagiarism", type="primary"):
                with st.spinner("Analyzing document... This may take a moment."):
                    try:
                        results = detector.analyze_document(text)
                        
                        if 'error' in results:
                            st.error(f"Analysis failed: {results['error']}")
                        else:
                            st.success("âœ… Analysis complete!")
                            display_analysis_results(results)
                            
                            # Export options
                            st.subheader("ğŸ’¾ Export Results")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                # JSON export
                                json_str = json.dumps(results, indent=2, ensure_ascii=False)
                                st.download_button(
                                    label="ğŸ“„ Download JSON Report",
                                    data=json_str,
                                    file_name=f"plagiarism_report_{uploaded_file.name}.json",
                                    mime="application/json"
                                )
                            
                            with col2:
                                # Summary export
                                summary = f"""DocInsight Plagiarism Analysis Report
================================================

Document: {uploaded_file.name}
Analysis Date: {time.strftime('%Y-%m-%d %H:%M:%S')}

OVERALL STATISTICS:
- Total Sentences Analyzed: {results['overall_stats']['total_sentences']}
- Average Similarity Score: {results['overall_stats']['avg_fused_score']:.3f}
- Maximum Similarity Score: {results['overall_stats']['max_fused_score']:.3f}
- High Risk Sentences: {results['overall_stats']['high_confidence_count']}
- Medium Risk Sentences: {results['overall_stats']['medium_confidence_count']}
- Low Risk Sentences: {results['overall_stats']['low_confidence_count']}
- High Risk Percentage: {results['overall_stats']['high_risk_ratio']*100:.1f}%

RISK ASSESSMENT:
{
    "HIGH RISK: Immediate attention required!" if results['overall_stats']['high_confidence_count'] > 0 
    else "MEDIUM RISK: Review recommended." if results['overall_stats']['medium_confidence_count'] > 0 
    else "LOW RISK: No significant issues detected."
}

Generated by DocInsight Enhanced v2.0
"""
                                st.download_button(
                                    label="ğŸ“‹ Download Summary Report",
                                    data=summary,
                                    file_name=f"plagiarism_summary_{uploaded_file.name}.txt",
                                    mime="text/plain"
                                )
                    
                    except Exception as e:
                        st.error(f"âŒ Analysis failed: {e}")
        else:
            st.error("âŒ Failed to extract text from the uploaded file.")
    
    # Information section
    st.sidebar.markdown("""
    ## â„¹ï¸ About DocInsight Enhanced
    
    **Version 2.0** represents a complete transformation from the original demo system:
    
    ### ğŸ”„ What's New:
    - **Real Dataset Integration**: 50,000+ sentences from PAWS, Wikipedia, and academic sources
    - **Advanced ML Pipeline**: SentenceTransformers + Cross-encoder reranking
    - **One-Click Operation**: No manual corpus upload needed
    - **Enhanced Reports**: Confidence scoring and detailed analysis
    
    ### ğŸ›¡ï¸ Privacy Notice:
    - Documents are processed locally
    - No data is stored permanently
    - Analysis results are not shared
    
    ### ğŸ¯ Best Results:
    - Upload complete documents (not fragments)
    - Ensure text is in English
    - Academic and technical content works best
    """)

if __name__ == "__main__":
    main()